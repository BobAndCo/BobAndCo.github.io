<!doctype html>
<html>

<head>

    <!-- Style -->
    <link href='style.css' rel='stylesheet'>

    <!-- LaTeX integration -->

    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css" integrity="sha384-vKruj+a13U8yHIkAyGgK1J3ArTLzrFGBbBc0tDp4ad/EyewESeXE/Iv67Aj8gKZ0" crossorigin="anonymous">

    <!-- The loading of KaTeX is deferred to speed up page rendering -->
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.js" integrity="sha384-PwRUT/YqbnEjkZO0zZxNqcxACrXe+j766U2amXcgMg5457rve2Y7I6ZJSm2A0mS4" crossorigin="anonymous"></script>

    <!-- To automatically render math in text elements, include the auto-render extension: -->
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/contrib/auto-render.min.js" integrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05" crossorigin="anonymous"
        onload="renderMathInElement(document.body);"></script>
  </head>

<body>

    <h1> Riesz Representation Theorem on Finite Dimensional Inner Product Spaces</h1>

    <p>
        The Riesz Representation Theroem that we will see in the first half of this post is a theorem for finite dimensional inner product spaces that links the study of linear functionals 
        with that of inner products. It gives us a way of looking at linear functionals in terms of specific vectors. 
    </p>

    <div id="container">
    <b>Riesz Representation Theorem</b>
    <p>
        Suppose \(V\) is a finite dimensional inner product space then, for every linear functional \(\varphi\) there is a unique 
        vector \(u \in V\) such that 
        \[
            \varphi(v) = \langle v, u \rangle
        \] 
    </p>
    </div>

    <p>
        Before jumping into the proof of the Riesz Representation Theorem there are two lemmas that need to be proved. The first is the following lemma
    </p>

    <div id="container">
    <b>Lemma I</b>
        <p>
        Given an orthonormal basis \(\alpha = \{e_{1}, \dots, e_{n}\}\) of \(V\) then any vector \(v \in V\) can be written 
        \(\sum_{i=1}^{n}\langle v, e_{i}\rangle e_{i}\)
        </p>
    </div>

    <div id="proof">
    <p>
        Proof: We start by the fact that \(\alpha\) is a basis, then \(v = \sum_{i=1}^{n}a_{i}e_{i}\). Note now that 
        \[
        \begin{aligned}
            \langle v, e_{j}\rangle &= \left\langle \sum_{i=1}^{n}a_{i}e_{i}, e_{j}\right\rangle \\
                                    &= \sum_{i=1}^{n}a_{i}\langle e_{i}, e_{j} \rangle \\
                                    &= a_{j}
        \end{aligned}
        \]
        This comes from the fact \(\langle e_{i}, e_{j} \rangle = \delta_{ij}\). Hence we may write \(v = \sum_{i=1}^{n}\langle v, e_{i}\rangle e_{i}\).
    </p>
    </div>

    <p>
        The second lemma is the following. 
    </p>

    <div id="container">
        <b>Lemma II</b>
        <p>
        If for every \(v \in V\), if \(u \in V\) has the property that \(\langle v, u \rangle = 0\) then \(u = 0\).
        </p>
    </div>

    <div id="proof">
    <p>
        Proof: If \(v = u\) then \(\langle u, u \rangle = 0 \iff u = 0\).
    </p>
    </div>

    <p>
        We will now use these two lemmas to prove the statement of the theorem. The point of these theorems should be obvious, in the sense that these are 
        very natural steps that one might take when trying to prove this theorem. The linearity of the function and the inner product is also quite useful.
    </p>

    <div id="proof">
    <p>
        Proof: Let \(e_{1}, \dots, e_{n}\) be an orthonormal basis for \(V\). Now \(v = \sum_{i=1}^{n}a_{i}e_{i}\) then since \(\varphi\) is a linear 
        functional we may do the following
        \[
        \begin{aligned}
            \varphi(v) &= \varphi\left(\sum_{i=1}^{n}a_{i}e_{i}\right) \\
                       &= \sum_{i=1}^{n}a_{i}\varphi(e_{i}) \\
                       &= \sum_{i=1}^{n}\langle v, e_{i} \rangle\varphi(e_{i}) \\
                       &= \sum_{i=1}^{n}\langle v, \overline{\varphi(e_{i})}e_{i}\rangle \\
                       &= \left\langle v, \sum_{i=1}^{n}\overline{\varphi(e_{i})}e_{i}\right\rangle
        \end{aligned}
        \]
        So we see that \(u = \sum_{i=1}^{n}\overline{\varphi(e_{i})}e_{i}\). Now we must show that this choice of \(u\) is unique. 
    </p>

    <p>
        To show that this is unique, suppose we had \(u_{1}, u_{2}\) such that \(\varphi(v) = \langle v, u_1 \rangle = \langle v, u_2 \rangle\) but note 
        that, then for every \(v \in V\)
        \[
        \begin{aligned}
            0 &= \varphi(v) - \varphi(v) \\
              &= \langle v, u_{1} \rangle - \langle v, u_{2} \rangle \\
              &= \langle v, u_{1} - u_{2} \rangle
        \end{aligned}
        \]
        but since \(\langle v, u_{1} - u_{2} \rangle = 0\) then \(u_{1} = u_{2}\) so this shows the uniqueness of the choice of \(u\).
    </p>
    </div>
    
    <p>
	Armed with this we now want to be able to use this in the study of linear operators. After all the goal of the Riesz Representation Theorem was to be able to study linear operators on a finite dimensional inner product space.
	Now we will introduce a new classification of linear operators and that is of the adjoint. However before going any further it is important that we show that such a linear operator may exist. Note that we are not going to go 
	further than just showing that Riesz Represention Thoeorem guareentees the existence of adjoints. 
    </p>

    <p>
	Suppose we have an inner product space \(V\) and we have a linear operator \(T \in \mathcal{L}(V)\) we may be interested with how this operator interacts with the inner product. More specifically if we consider 
	\(\langle Tv, w \rangle\) we may want to "bring" over the operator to the second argument. It would be really convient if there were a linear operator \(T^{*} \in \mathcal{L}(V)\) such that 
	\(\langle Tv, w \rangle = \langle v, T^{*}w \rangle\). To prove the existence of such a linear operator we will make use of the Riesz Representation Theorem. 
    </p>

    <div id="container">
    	<b>Lemma III</b>
	<p>
		Let \(V\) be inner product space and \(T \in \mathcal{L}(V)\) then there is a linear operator \(T^{*} \in \mathcal{L}(V)\) such that \(\langle Tv, w \rangle = \langle v, T^{*}w \rangle\) for every \(v, w \in V\)
	</p>
    </div>

    <div id="proof">
	<p>
		Proof: Starting with \(T \in \mathcal{L}(V)\) then for every \(w \in V\) the map \(\varphi_{w}(v) = \langle Tv, w \rangle\) defines a linear functional, the proof of that claim follows directly from the linearity of \(T\) and
		the inner product. Now by the Riesz Representation Theorem there is a \(w_{*} \in V\) such that \(\langle Tv, w \rangle = \varphi(v) = \langle v, w_{*} \rangle\) we may now define \(T^{*}w = w_{*}\). 
		This now shows that there is map that achieves what we want, the only thing left to prove is that this is actually linear. Note that that if we consider 
		\[
		\begin{aligned}
			\langle v, T^{*}(aw_{1} + w_{2}) \rangle &= \langle Tv, aw_{1} + w_{2} \rangle \\ 
								 &= \langle Tv, aw_{1} \rangle + \langle Tv, w_{2} \rangle \\
								 &= \overline{a} \langle v, T^{*}w_{1} \rangle + \langle v, T^{*}w_{2} \rangle \\
								 &= \langle v, aT^{*}w_{1} \rangle + \langle v, T^{*}w_{2} \rangle \\
								 &= \langle v, aT^{*}w_{1} + T^{*}w_{2} \rangle
		\end{aligned}
		\]
		Now since this is true for every \(v \in V\) we may conclude that \(T^{*}(aw_{1} + w_{2}) = aT^{*}w_{1} + T^{*}w_{2}\) hence \(T^{*} \in \mathcal{L}(V)\)
	</p>
    </div>

    <p>
	So as we can see, the Riesz Representation theorem is a very powerful tool for us to use. The adjoint is interesting in its own right, it allows us insight into these linear maps that are otherwise difficult to come up with. But
	nonetheless, this post not about the uses of the adjoint. 
    </p>

    <h1> Riesz Representation Theorem, But More General</h1>

    <p>
	This is not the whole story, however. In the sitation above we only consider when the inner product space is finite dimensional. But what 
	about the infinite dimensional case? Well there is nothing to fear because we have the complete picture here. Well to say that this theorem works for every linear functional would be a strecth, however there is a special class of 
	linear functionals that are nice enough for this, otherwise tough, theorem to hold. 
    </p>

    <div id="container">
	<b> Riesz Representation Theorem </b>
	<p>
		Suppose \(H\) is a Hilbert Space then for every continous linear functional \(\varphi\) there is a unique vector \(u \in H\) such that 
		\[
            		\varphi(v) = \langle v, u \rangle
        	\] 

	</p>
	Moreover the vector \(u\) is called the Riesz Representation of \(\varphi\)
    </div>
	
	<p>
	Before we jump into details about this theorem, there is something interesting going on about with this, and that is that this theorem implies that every linear functional on a finite dimensional Hilbert space is continous.
	Moreover, every linear functional on a finite dimensional Hilbert space is bounded. Let us first define what these terms even mean. To do this we shall define a topology on these Hilbert spaces. The best choice of topology is the one induced by the metric.
	</p>
	
	<p>
	For the definitions to follow suppose that \((H, d)\) is a Hilbert space with the metric \(d: H \times H \to \mathbb{R}\) defined in the usual way.
	</p>
	
	<div id="container">
	<b>Open Balls</b>
	<p>
		The open ball of radius \(\epsilon > 0\) around a point \(p\) is the set 
		\[
			B(p, \epsilon) = \{q \in H \mid d(p, q) < \epsilon\}
		\]
	</p>
	</div>
	<p>
	Given these open balls we can define a basis for the metric topolgy.
	</p>
	<div id="container">
	<b> The Topology on Hilbert Spaces </b>
	<p>
		Let \(\mathcal{B} = \{B(p, \epsilon) \mid \epsilon > 0, p \in H\}\), then this forms a basis for a topology on \((H, d)\)	
	</p>
	</div>
	<p>
	One can confirm for themselves that this is indeed a basis. The main idea is that for every point in \(H\) we can choose \(B(p, \epsilon)\) for any \( \epsilon \) 
    that is small enough and that is in \( \mathcal{B}\). Now if we take the intersection of two elements, \(B_1, B_2 \in \mathcal{B}\) it is either 
    empty or not. If it is not then for each \(x\) in the intersection we can again take a small enough \(\epsilon\) such that \(x \in B(x, \epsilon) \subset B_1 \cap B_2\).
    Note that these alone do not constitute that \(\mathcal{B}\) is a basis, but rather these are the starting points for the arguments.
    </p>

    <p> 
    However the important fact here is that this topology does something interesting. It makes the addition and scalar multiplication continous maps. 
    We will now define something new
    </p>
    <div id="container">
    <b> Topological Vector Space </b>
    <p>
        A topological space \((H, \mathcal{T})\) is called a topological vector space if \(H\) is a vector space and the addition 
        and multiplication are continous with respect to \(\mathcal{T}\).
    </p>
    </div> 
	<p>
        One might ask, what it means for a function to be continous 
        We will now show that if \((H, d)\) is a Hilbert space then it is a topological vector space with the metric topology induced 
        by \(d\). 
    </p>
</body>
</html>